{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naufrágio Titanic.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLjFmF0Yp6VH1AasAaziI3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielTrentino/Competicoes/blob/master/Naufr%C3%A1gio_Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZYy0wpj1F6P",
        "colab_type": "text"
      },
      "source": [
        "#Desafio Kaggle do Titanic:\n",
        "\n",
        "**O Desafio do Titanic** é uma das competições mais conhecidas no [Kaggle.com](https://www.kaggle.com/c/titanic) e, sem sombra de dúvidas, é uma das melhores primeiras experiências para \"mergulhar\" no mundo de *Machine Learning*.\n",
        "\n",
        "Com o objetivo único de **familiarizar os novos Cientistas de Dados com as estrutura e as dinâmicas do Kaggle**, O desafio do Titanic é o equivalente ao \"Olá Mundo!\" para os Cientistas de Dados.\n",
        "\n",
        "![](https://github.com/GabrielTrentino/Competicoes/blob/master/img/0Titanic.jpg?raw=true)\n",
        "\n",
        "Sem dúvidas, o naufrágio do Titanic é um dos incidentes mais conhecidos pelo mundo, foi digno do famoso filme de mesmo nome. O evento ocorreu no dia 15 de Abril de 1912 **resultando na morte de 1502 pessoas de 2224**(entre passageiros e tripulação). \n",
        "\n",
        "Enquanto houve algum elemento de sorte envolvida nessa chance de sobrevivência do naufragio, houve uma maior probabilidade de sobrevivência entre um grupo e outro. E nosso objetivo é investigar essas chances, proporções, probabilidades com os dados fornecidos pelo Kaggle!\n",
        "\n",
        "Essa competição, além da Análise Exploratória de Dados, também pede a elaboração de um **Modelo Preditivo** de *Machine Learning* **capaz de dizer se uma pessoa teria ou não chances de sobreviver.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybm5-MtFtHKq",
        "colab_type": "text"
      },
      "source": [
        "##Importação das Bibliotecas Essenciais:\n",
        "\n",
        "Inicialmente, importaremos as bibliotecas essenciais para manipulação dos dados (como Pandas, Numpy) e outras focadas para criação de gráficos (Matplotlib.Pyplot e Seaborn)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3AxmT22mOtp",
        "colab_type": "code",
        "outputId": "34522983-dfc7-45cd-91c6-851640849f6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#Importando as bibliotecas necessárias:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3ZMqBbuYaU3",
        "colab_type": "text"
      },
      "source": [
        "##Importação dos Arquivos disponibilizados no Kaggle:\n",
        "\n",
        "A Importação desses arquivos são feitos de forma simplificada através do seguinte [Tutorial em Inglês](https://medium.com/@opalkabert/downloading-kaggle-datasets-into-google-colab-fb9654c94235). O processo de Identificação de Upload do Token gerado pelo Kaggle é ocultado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQzqQ__ymYd6",
        "colab_type": "code",
        "outputId": "74366c3f-72ac-4fb6-e9de-e675116d821c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "#Pedindo ao Pandas que leia os arquivos \".csv\" e transforme em DataFrame:\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "submis = pd.read_csv('gender_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d18202ee15f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msubmis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gender_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File train.csv does not exist: 'train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqpUvFdcZdSq",
        "colab_type": "text"
      },
      "source": [
        "O arquivo `train.csv` contém as informações relativas ao treino do modelo (contendo a informação se a pessoa sobreviveu ou não). \n",
        "\n",
        "O arquivo `test.csv` contém as informações relativas ao teste do modelo, exceto as informações de sobrevivência."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0js7BxXtvB7",
        "colab_type": "text"
      },
      "source": [
        "#Análise Exploratória:\n",
        "A Análise Exploratória é composta por técnicas simples que buscam extrair ou ilustrar as informações contidas nos dados, sem conter nenhuma alteração significativa. Com essa definição, utilizaremos da Visualização de Dados para aumentar a eficiência dessa exploração inicial.\n",
        "\n",
        "A idéia dessa Análise é trabalharmos ela como uma exploração de hipoteses ou duvidas que possamos ter sobre um Data Set e, por isso, nada melhor que utilizarmos perguntas para instigarmos ou elucidar o que queremos achar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFSC6vNLXzjb",
        "colab_type": "text"
      },
      "source": [
        "##Q1. Quais são as variáveis do DataSet?\n",
        "A primeira pergunta a se fazer é sobre quais são as variáveis iremos utilizar nos modelos, para entendermos melhor, utilizaremos a função `.head()` que nos mostrará as primeiras entradas do DataSet e cruzaremos as informações com o que é descrito no Kaggle para criarmos nosso **Dicionário de Variáveis**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXhVbH6etAxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5MxUOzytOyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRIUb82WtFGg",
        "colab_type": "text"
      },
      "source": [
        "Aqui estará o Dicionário explicando cada variável:\n",
        "\n",
        "*  `PassengerId`- \n",
        "*  `Survived`- \n",
        "*  `Pclass` - \n",
        "*  `Name` - \n",
        "*  `Sex` - \n",
        "*  `Age` - \n",
        "*  `SibSp` -  \n",
        "*  `Parch` - \n",
        "*  `Ticket` - \n",
        "*  `Fare` - \n",
        "*  `Cabin` - \n",
        "*  `Embarked` - "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x97JoQEatJ1a",
        "colab_type": "text"
      },
      "source": [
        "##Q2. Quais são as dimensões do Data Frame de Treino e Teste?\n",
        "\n",
        "Um dos passos principais da Análise Exploratória é entender as dimensões desses Data Frames, pois assim, conseguiremos ter uma noção de quantos dados estamos analisando e manipulando."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CSR7Z3JxsXPF",
        "colab": {}
      },
      "source": [
        "#Imprimindo a quantidade de linhas e colunas dos Data Frames:\n",
        "print(\"O Data Frame de Treino tem: {} linhas e {} colunas\".format(train.shape[0], train.shape[1]))\n",
        "print(\"O Data Frame de Teste tem: {} linhas e {} colunas\".format(test.shape[0], test.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtOMouaGtrNs",
        "colab_type": "text"
      },
      "source": [
        "##Q3. Qual a Porcentagem de Instâncias (Linhas) do Data Frame de Treino sobre o Total?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vYDz-iksX2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Imprimindo a % de dados de treino sobre o total:\n",
        "print(\"Temos {:.3f}% dos dados estão como treino\".format(train.shape[0]/(train.shape[0]+test.shape[0])*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XDZ3wvtbBO0",
        "colab_type": "text"
      },
      "source": [
        "##Q4. Qual a quantidade de dados nulos existentes (NaN)?\n",
        "Uma das preocupações que devemos ter logo na Análise Exploratória é de sabermos a quantidade de dados nulos existentes no Data Frame, pois haverá alguns modelos que não conseguirão trabalhar com esses tipos de dados e, para isso, deveremos contornar de alguma forma. Usamos as funções `.isnull().sum()` que irão verificar se a entrada possui valor nulo e, em seguida, somar (`.sum()`) a quantidade de valores verdadeiros (que são representados por `True` ou `1`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQM87dGcslKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Quantos dados nulos estão presentes nesse Data Frame por coluna:\n",
        "train.isnull().sum().sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xWCF5FQbjsw",
        "colab_type": "text"
      },
      "source": [
        "##Q5. Quais são os tipos de dados das nossas colunas?\n",
        "Outra preocupação que deve ser investigada logo no começo, pois podemos achar que estamos manipulando valores númericos como `int64` ou `float64`, mas na verdade estaríamos trabalhando com `strings` que são acusados como `object`.\n",
        "\n",
        "Para isso, utilizamos o atributo `.dtypes`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiTLuM3NsmS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Verificando os tipos das variáveis:\n",
        "train.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBpbhc7cc8VM",
        "colab_type": "text"
      },
      "source": [
        "##Q6. Quais são as Descrições Estatísticas?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyNbkBocs-pK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Informações Estatísticas Descritivas.\n",
        "train.describe().round(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AzJ_ws0eCQQ",
        "colab_type": "text"
      },
      "source": [
        "Aqui terão gráficos:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv2Xih_Vu0P2",
        "colab_type": "text"
      },
      "source": [
        "#Primeiras Correções:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs305iDMu4Pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train[\"Sex_bin\"] = train['Sex'].map(lambda x: 0 if x == 'female' else 1)\n",
        "test[\"Sex_bin\"] = test['Sex'].map(lambda x: 0 if x == 'female' else 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi9jZJUSETGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "variaveis = ['Sex_bin', 'Age']\n",
        "\n",
        "X = train[variaveis].fillna(-1)\n",
        "y = train['Survived']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWPKx7DIu18p",
        "colab_type": "text"
      },
      "source": [
        "#Modelo de Machine Learning:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KE3C31Nvfn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train[['Sex_bin', 'Age']]\n",
        "X_train.fillna(-1, inplace = True)\n",
        "y_train = train.Survived\n",
        "\n",
        "X_test = test[['Sex_bin', 'Age']]\n",
        "X_test.fillna(-1, inplace = True)\n",
        "y_test = test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6qia7Cbt44M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "modelo = RandomForestClassifier(n_estimators=100, n_jobs=1, random_state=0)\n",
        "modelo.fit(X_train, y_train)\n",
        "\n",
        "y_pred = modelo.predict(X_test)\n",
        "print(cross_val_score(modelo, X=X_train, y = y_train, cv=10).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bharNqNaChk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Validação Cruzada:\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(2, shuffle = True, random_state = 0)\n",
        "\n",
        "resultados = []\n",
        "\n",
        "for linhas_treino, linhas_valid in kf.split(X):\n",
        "  # print('Treino: ', linhas_treino.shape[0])\n",
        "  # print('Valid: ', linhas_valid.shape)\n",
        "  X_train, X_valid = X.iloc[linhas_treino], X.iloc[linhas_valid]\n",
        "  y_train, y_valid = y.iloc[linhas_treino], y.iloc[linhas_valid]\n",
        "  modelo = RandomForestClassifier(n_estimators=100, n_jobs=1, random_state=0)\n",
        "  modelo.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = modelo.predict(X_valid)\n",
        "  acc = np.mean(y_valid==y_pred)\n",
        "  resultados.append(acc)\n",
        "np.mean(resultados)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4LTZa0PGyFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import RepeatedKFold\n",
        "kf = RepeatedKFold(2, n_repeats=10, random_state = 10)\n",
        "\n",
        "resultados = []\n",
        "\n",
        "for linhas_treino, linhas_valid in kf.split(X):\n",
        "  # print('Treino: ', linhas_treino.shape[0])\n",
        "  # print('Valid: ', linhas_valid.shape)\n",
        "  X_train, X_valid = X.iloc[linhas_treino], X.iloc[linhas_valid]\n",
        "  y_train, y_valid = y.iloc[linhas_treino], y.iloc[linhas_valid]\n",
        "  modelo = RandomForestClassifier(n_estimators=100, n_jobs=1, random_state=0)\n",
        "  modelo.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = modelo.predict(X_valid)\n",
        "  acc = np.mean(y_valid==y_pred)\n",
        "  resultados.append(acc)\n",
        "np.mean(resultados)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZG4e7hyHgFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(resultados);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y-x_r5C-Bai",
        "colab_type": "text"
      },
      "source": [
        "#Regressão Logistica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cDFn1gW-FoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "X_train = train.drop('Survived', axis = 1)\n",
        "X_train = X_train[['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_bin']]\n",
        "X_test = test[['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_bin']]\n",
        "X_train.fillna(-1, inplace = True)\n",
        "X_test.fillna(-1, inplace = True)\n",
        "\n",
        "y_train = train['Survived']\n",
        "y_test = test\n",
        "\n",
        "modelo = LogisticRegression(max_iter=X_train.shape[0])\n",
        "modelo.fit(X_train, y_train)\n",
        "y_pred = modelo.predict(X_test)\n",
        "\n",
        "print('{:.4f}'.format(cross_val_score(modelo, X=X_train, y = y_train, cv=10).mean()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz_hhVXSIWmG",
        "colab_type": "text"
      },
      "source": [
        "#Utilizando outras Variáveis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLKHuRFBIYHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "variaveis = ['Sex_bin', 'Age', 'Pclass', 'SibSp', 'Parch', 'Fare']\n",
        "\n",
        "X = train[variaveis].fillna(-1)\n",
        "y = train['Survived']\n",
        "\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "kf = RepeatedKFold(3, n_repeats=10, random_state = 10)\n",
        "\n",
        "resultados = []\n",
        "\n",
        "for linhas_treino, linhas_valid in kf.split(X):\n",
        "  # print('Treino: ', linhas_treino.shape[0])\n",
        "  # print('Valid: ', linhas_valid.shape)\n",
        "  X_train, X_valid = X.iloc[linhas_treino], X.iloc[linhas_valid]\n",
        "  y_train, y_valid = y.iloc[linhas_treino], y.iloc[linhas_valid]\n",
        "  modelo = RandomForestClassifier(n_estimators=100, n_jobs=1, random_state=0)\n",
        "  modelo.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = modelo.predict(X_valid)\n",
        "  acc = np.mean(y_valid==y_pred)\n",
        "  resultados.append(acc)\n",
        "np.mean(resultados)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V2TQTF-Jhm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelo = RandomForestClassifier(n_estimators=100, n_jobs=1, random_state=0)\n",
        "modelo.fit(X,y)\n",
        "\n",
        "p = modelo.predict(test[variaveis].fillna(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRwVQIZrddhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfL1PP5KPHgk",
        "colab_type": "text"
      },
      "source": [
        "#Criando novas Variáveis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEKF-GerQNAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "X = train[variaveis].fillna(-1)\n",
        "y = train['Survived']\n",
        "\n",
        "kf = RepeatedKFold(3, n_repeats=10, random_state = 10)\n",
        "\n",
        "resultados = []\n",
        "\n",
        "for linhas_treino, linhas_valid in kf.split(X):\n",
        "  # print('Treino: ', linhas_treino.shape[0])\n",
        "  # print('Valid: ', linhas_valid.shape)\n",
        "  X_train, X_valid = X.iloc[linhas_treino], X.iloc[linhas_valid]\n",
        "  y_train, y_valid = y.iloc[linhas_treino], y.iloc[linhas_valid]\n",
        "  modelo = GaussianNB()\n",
        "  modelo.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = modelo.predict(X_valid)\n",
        "  acc = np.mean(y_valid==y_pred)\n",
        "  resultados.append(acc)\n",
        "np.mean(resultados)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Jtkdw_JywOB",
        "colab_type": "text"
      },
      "source": [
        "#Criando a Subscrição:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SSMsIGQyzBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = pd.Series(p, index = test['PassengerId'], name= 'Survived')\n",
        "sub.to_csv(\"segundo_modelo.csv\", header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}